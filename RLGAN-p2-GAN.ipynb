{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Assesment Task #1: Colorizing Images with Generative Adversarial Networks\n",
    "TÃ©cnicas Generativas y Aprendizaje por Refuerzo - Curso 2024/2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies and Set General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.9.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.layers import (\n",
    "    Activation, AveragePooling2D, BatchNormalization,\n",
    "    Conv2D, Dense, Dropout, Flatten, LeakyReLU, UpSampling2D\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# Enable memory growth for GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = 32\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "WORKDIR = \"results_p2\"\n",
    "\n",
    "# Create directories\n",
    "Path(WORKDIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(f\"{WORKDIR}/GAN_results\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(images, debug=False):\n",
    "    \"\"\"\n",
    "    This function converts a list of RGB images to the LAB color space, and separates the L channel from the A and B channels.\n",
    "    The images are normalized and reshaped to the appropriate dimensions for the model.\n",
    "\n",
    "    Parameters:\n",
    "    images (list): A list of RGB images\n",
    "    debug (bool): If True, the function will display the original and converted images\n",
    "\n",
    "    Returns:\n",
    "    X (np.array): A numpy array of L channels of the images\n",
    "    Y (np.array): A numpy array of A and B channels of the images\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in images:\n",
    "        lab_image_array = rgb2lab(i / 255)  # Convert the image from RGB to LAB color space\n",
    "        x = lab_image_array[:, :, 0]  # Get the L channel\n",
    "        y = lab_image_array[:, :, 1:]  # Get the A and B channels\n",
    "        y /= 128  # normalize\n",
    "\n",
    "        if debug:  # If debug is True, display the original and converted images\n",
    "            fig = plt.figure()\n",
    "            fig.add_subplot(1, 2, 1)\n",
    "            plt.imshow(i / 255)\n",
    "\n",
    "            fig.add_subplot(1, 2, 2)\n",
    "            plt.imshow(lab2rgb(np.dstack((x, y * 128))))\n",
    "            plt.show()\n",
    "\n",
    "        X.append(x.reshape(IMAGE_SIZE, IMAGE_SIZE, 1))  # Reshape the L channel and append to the list\n",
    "        Y.append(y)  # Append the A and B channels to the list\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)  # Convert the list to a numpy array\n",
    "    Y = np.array(Y, dtype=np.float32)  # Convert the list to a numpy array\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def load_data(force=False):\n",
    "    \"\"\"\n",
    "    This function loads the CIFAR-10 dataset, processes it, and saves/loads the processed data to/from the disk.\n",
    "\n",
    "    Parameters:\n",
    "    force (bool): If True, the function will reprocess the data even if it already exists on the disk\n",
    "\n",
    "    Returns:\n",
    "    X_train, Y_train, X_test, Y_test (np.array): Numpy arrays of the training and testing data\n",
    "    \"\"\"\n",
    "    is_saved_arrays_exist = os.path.isfile(os.path.join(WORKDIR, 'X_train.npy'))  # Check if the processed data already exists on the disk\n",
    "\n",
    "    if not is_saved_arrays_exist or force:  # If the processed data does not exist or if force is True, process the data\n",
    "        (train_images, _), (test_images, _) = cifar10.load_data()  # Load the CIFAR-10 dataset\n",
    "        X_train, Y_train = generate_dataset(train_images)  # Process the training images\n",
    "        X_test, Y_test = generate_dataset(test_images)  # Process the testing images\n",
    "        print('Saving processed data')\n",
    "        np.save(os.path.join(WORKDIR, 'X_train.npy'), X_train)  # Save the processed training data to the disk\n",
    "        np.save(os.path.join(WORKDIR, 'Y_train.npy'), Y_train)  # Save the processed training data to the disk\n",
    "        np.save(os.path.join(WORKDIR, 'X_test.npy'), X_test)  # Save the processed testing data to the disk\n",
    "        np.save(os.path.join(WORKDIR, 'Y_test.npy'), Y_test)  # Save the processed testing data to the disk\n",
    "    else:  # If the processed data exists and force is False, load the data from the disk\n",
    "        print('Loading processed data')\n",
    "        X_train = np.load(os.path.join(WORKDIR, 'X_train.npy'))  # Load the processed training data from the disk\n",
    "        Y_train = np.load(os.path.join(WORKDIR, 'Y_train.npy'))  # Load the processed training data from the disk\n",
    "        X_test = np.load(os.path.join(WORKDIR, 'X_test.npy'))  # Load the processed testing data from the disk\n",
    "        Y_test = np.load(os.path.join(WORKDIR, 'Y_test.npy'))  # Load the processed testing data from the disk\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data to Drive\n"
     ]
    }
   ],
   "source": [
    "# Load the processed training and testing data\n",
    "X_train, Y_train, X_test, Y_test = load_data()\n",
    "\n",
    "# Create TensorFlow datasets from the training and testing data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "\n",
    "# Shuffle the training dataset and batch both datasets\n",
    "# SHUFFLE_BUFFER_SIZE determines the randomness of the shuffling\n",
    "# BATCH_SIZE determines the number of samples that will be propagated through the network at once\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_model():\n",
    "    \"\"\"\n",
    "    This function builds the generator model for the GAN. The generator is responsible for generating new, fake images.\n",
    "    It uses a series of Conv2D, BatchNormalization, and UpSampling2D layers.\n",
    "\n",
    "    Returns:\n",
    "    model (Sequential): The generator model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Suggested architecture:\n",
    "    # Downsampling\n",
    "        # Add a series of Conv2D layers followed by BatchNormalization layers\n",
    "        # Conv2D layers are used for the convolution operation that extracts features from the input images\n",
    "        # Conv2D layers with stride=1 preserve the dimensions of the image\n",
    "        # Conv2D layers with stride=2 downsample the image (i.e., reduce the dimensions of the image by half)\n",
    "        # BatchNormalization layers are used to normalize the activations of the previous layer at each batch\n",
    "        # ReLU activation function is used to add non-linearity to the output of the previous layer\n",
    "        # Padding is set to 'same' to preserve the dimensions of the image\n",
    "        # Repeat this series of layers N times\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), strides=2, padding='same', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(512, (3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Upsampling\n",
    "        # UpSampling2D layer is used to increase the dimension of the image\n",
    "        # Add as many UpSampling2D layers as Conv2D layers with stride=2 to upsample the image to its original dimensions\n",
    "        # Add a series of Conv2D layers followed by BatchNormalization layers\n",
    "        # BatchNormalization layers are used to normalize the activations of the previous layer at each batch\n",
    "        # ReLU activation function is used to add non-linearity to the output of the previous layer\n",
    "    \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Output layer\n",
    "        # Add a Conv2D layer with 2 filters to output the A and B LAB channels of the image\n",
    "        # Activation layer is used to apply the tanh activation function to the output\n",
    "        # tanh activation function is used because the pixels of the output images range from -1 to 1\n",
    "\n",
    "    model.add(Conv2D(2, (3, 3), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_model():\n",
    "    \"\"\"\n",
    "    This function builds the discriminator model for the GAN. The discriminator is responsible for distinguishing real images from fake ones.\n",
    "    It is recommended to use a series of Conv2D, Dropout, AveragePooling2D, Flatten, Dense, LeakyReLU, BatchNormalization, and Activation layers to create the model.\n",
    "\n",
    "    Returns:\n",
    "    model (Sequential): The discriminator model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Suggested architecture:\n",
    "    # Convolution blocks\n",
    "        # Add a series of Conv2D layers followed by Dropout\n",
    "        # Conv2D layers are used for the convolution operation that extracts features from the input images\n",
    "        # Dropout layers are used to prevent overfitting by randomly setting a fraction rate of input units to 0 at each update during training time\n",
    "        # Repeat this series of layers N times\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), strides=2, padding='same', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), strides=2, padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), strides=2, padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, (3, 3), strides=2, padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, (3, 3), strides=2, padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Pooling and dense layers\n",
    "        # AveragePooling2D layer is used to downscale the image spatially\n",
    "        # Flatten layer is used to convert the 2D matrix of features into a vector that can be fed into a fully connected neural network classifier\n",
    "        # Dense layers are the regular deeply connected neural network layers\n",
    "        # LeakyReLU is a type of activation function that allows a small gradient when the unit is not active\n",
    "        # BatchNormalization layers are used to normalize the activations of the previous layer at each batch\n",
    "        # Dropout layers are used to prevent overfitting by randomly setting a fraction rate of input units to 0 at each update during training time\n",
    "\n",
    "    model.add(AveragePooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Output layer\n",
    "        # Add a Dense layer with 1 unit to output the probability of the input image being real or synthetic\n",
    "        # Activation layer is used to apply the sigmoid activation function to the output\n",
    "        # sigmoid activation function is used because the output is a probability between 0 and 1\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Generator and Discriminator Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weight of the GAN loss\n",
    "gan_loss_weight = 1\n",
    "\n",
    "# Define the regularization parameter for the generator's L2 loss\n",
    "l2_lambda = 150 \n",
    "\n",
    "# Define the loss function for the discriminator\n",
    "# Binary Cross Entropy is used as the loss function since we are dealing with a binary classification problem (real vs fake images)\n",
    "cross_entropy = BinaryCrossentropy() \n",
    "\n",
    "def discriminator_loss(disc_real_output: tf.Tensor, disc_generated_output: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    This function calculates the total loss for the discriminator.\n",
    "\n",
    "    Parameters:\n",
    "    disc_real_output (Tensor): The discriminator's prediction on the real images\n",
    "    disc_generated_output (Tensor): The discriminator's prediction on the generated (fake) images\n",
    "\n",
    "    Returns:\n",
    "    total_disc_loss (Tensor): The total loss for the discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    total_disc_loss = 0  # Initialize the total loss for the discriminator\n",
    "    \n",
    "    # Calculate the cross entropy loss for the real images\n",
    "    real_loss = cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    \n",
    "    # Calculate the cross entropy loss for the generated (synthetic) images\n",
    "    generated_loss = cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # Calculate the total loss for the discriminator by adding the losses for the real and generated images\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    \n",
    "    # Return the total loss for the discriminator\n",
    "    return total_disc_loss\n",
    "\n",
    "\n",
    "def generator_loss(disc_generated_output: tf.Tensor, gen_output: tf.Tensor, target: tf.Tensor) -> tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"\n",
    "    This function calculates the total loss for the generator.\n",
    "\n",
    "    Parameters:\n",
    "    disc_generated_output (Tensor): The discriminator's prediction on the generated (fake) images\n",
    "    gen_output (Tensor): The generated (fake) images\n",
    "    target (Tensor): The real images\n",
    "\n",
    "    Returns:\n",
    "    total_gen_loss (Tensor): The total loss for the generator\n",
    "    gan_loss (Tensor): The GAN loss for the generator\n",
    "    l2_loss (Tensor): The L2 loss for the generator\n",
    "    \"\"\"\n",
    "    \n",
    "    total_gen_loss = 0  # Initialize the total loss for the generator\n",
    "    gan_loss = 0  # Initialize the GAN loss for the generator\n",
    "    l2_loss = 0  # Initialize the L2 loss for the generator\n",
    "    \n",
    "    # Calculate the GAN loss for the generator (i.e., the loss for fooling the discriminator)\n",
    "    gan_loss = cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # Calculate the L2 loss for the generator by comparing the generated images to the real images\n",
    "    l2_loss = tf.reduce_mean(tf.square(target - gen_output))\n",
    "    \n",
    "    # Calculate the total loss for the generator by adding the GAN loss (multiplied by its corresponding weight) and the L2 loss (multiplied by the regularization parameter)\n",
    "    total_gen_loss = gan_loss_weight * gan_loss + l2_lambda * l2_loss\n",
    "    \n",
    "    # Return the total loss, GAN loss, and L2 loss for the generator\n",
    "    return total_gen_loss, gan_loss, l2_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Generator and Discriminator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the generator and discriminator models\n",
    "generator = build_generator_model()\n",
    "discriminator = build_discriminator_model()\n",
    "\n",
    "# Print out the model summaries\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "\n",
    "# Define the optimizers for the generator and discriminator\n",
    "# Adam optimizer is used with a learning rate of 2e-4 and beta_1 (the exponential decay rate for the first moment estimates) of 0.5\n",
    "# It is recommended to experiment with different values for the learning rate. Beta_1 value of 0.5 is recommended for GANs\n",
    "# It is possible that the optimal learning rate for the generator and discriminator is different from each other\n",
    "gen_learning_rate = 2e-4\n",
    "gene_beta_1 = 0.5\n",
    "\n",
    "disc_learning_rate = 2e-4\n",
    "disc_beta_1 = 0.5\n",
    "\n",
    "generator_optimizer = Adam(gen_learning_rate, beta_1=gene_beta_1)\n",
    "discriminator_optimizer = Adam(disc_learning_rate, beta_1=disc_beta_1)\n",
    "\n",
    "# Define the directory for storing the training checkpoints\n",
    "checkpoint_dir = os.path.join(WORKDIR, 'training-checkpoints')\n",
    "# Define the prefix for the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# Create a checkpoint object which will be used to save and load the models and optimizers\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "# Create a manager for the checkpoint object, which will be responsible for saving and loading the checkpoints\n",
    "# max_to_keep parameter is set to 3, meaning that only the 3 most recent checkpoints will be kept\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and file for storing the TensorBoard summary logs\n",
    "summary_log_file = os.path.join(\n",
    "    WORKDIR, 'tf-summary', datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Create a summary writer for writing the summary logs\n",
    "summary_writer = tf.summary.create_file_writer(summary_log_file)\n",
    "\n",
    "@tf.function\n",
    "def train_step(input_image: tf.Tensor, target: tf.Tensor, epoch: int) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"\n",
    "    This function performs one training step for the generator and discriminator.\n",
    "\n",
    "    Parameters:\n",
    "    input_image (Tensor): The input image\n",
    "    target (Tensor): The target image\n",
    "    epoch (int): The current epoch number\n",
    "\n",
    "    Returns:\n",
    "    gen_total_loss (Tensor): The total loss for the generator\n",
    "    disc_loss (Tensor): The loss for the discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open a GradientTape context for automatic differentiation\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_total_loss = 0  # Initialize the total loss for the generator\n",
    "        gen_gan_loss = 0  # Initialize the GAN loss for the generator\n",
    "        gen_l2_loss = 0  # Initialize the L2 loss for the generator\n",
    "        disc_loss = 0  # Initialize the loss for the discriminator\n",
    "        \n",
    "        # Generate an image using the generator\n",
    "        # (remember to set training=True, since during training time BatchNormalization layers are applied using the batch mean and variance)\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        # Get the discriminator's predictions on the real and generated images\n",
    "        # (remember to set training=True, since during training time BatchNormalization layers are applied using the batch mean and variance)\n",
    "        disc_real_output = discriminator(target, training=True)\n",
    "        disc_generated_output = discriminator(gen_output, training=True)\n",
    "\n",
    "        # Calculate the losses for the generator and discriminator\n",
    "        # Use the discriminator_loss() and generator_loss() functions to calculate the losses\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "        gen_total_loss, gen_gan_loss, gen_l2_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "\n",
    "    # Calculate the gradients of the generator's and discriminator's losses with respect to the trainable variables of each model\n",
    "    # Use the gradient() method of the GradientTape object of each model to calculate the gradients of the losses with respect to the trainable variables of the corresponding model\n",
    "    # Model's trainable variables can be accessed using the trainable_variables attribute\n",
    "    gen_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Apply the gradients to the model's trainable variables\n",
    "    # Use the apply_gradients() method of the optimizer object to apply the gradients\n",
    "    # The apply_gradients() method takes a list of (gradient, variable) pairs\n",
    "    # zip() function can be used to iterate over two lists simultaneously (i.e., the gradients and the model's trainable variables)\n",
    "    generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "\n",
    "    # Write the losses to the summary logs\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_l2_loss', gen_l2_loss, step=epoch)\n",
    "        tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
    "\n",
    "    return gen_total_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The checkpoint manager will load the latest checkpoint if it exists\n",
    "# This will be used to resume training if the training process was interrupted\n",
    "# If no checkpoint exists, the models will be initialized from scratch\n",
    "\n",
    "# Restore the latest checkpoint using the checkpoint manager\n",
    "checkpoint.restore(manager.latest_checkpoint)\n",
    "\n",
    "# If a checkpoint was found and restored, print a message indicating the checkpoint file\n",
    "if manager.latest_checkpoint:\n",
    "    print('Restored from {}'.format(manager.latest_checkpoint))\n",
    "    \n",
    "# If no checkpoint was found, print a message indicating that the models are being initialized from scratch\n",
    "else:\n",
    "    print('Initializing from scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the epochs\n",
    "for e in tqdm(range(EPOCHS)):\n",
    "    # Record the start time of the epoch\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gen_loss_total = 0  # Initialize the total loss for the generator\n",
    "    disc_loss_total = 0  # Initialize the total loss for the discriminator\n",
    "    \n",
    "    # Loop over the training dataset\n",
    "    # COMPLETE\n",
    "        # Perform one training step and get the generator and discriminator losses\n",
    "        # COMPLETE\n",
    "        \n",
    "        # Add the losses to the total losses\n",
    "        # COMPLETE\n",
    "    \n",
    "    for input_image, target in train_dataset:\n",
    "        gen_loss, disc_loss = train_step(input_image, target, e)\n",
    "        gen_loss_total += gen_loss\n",
    "        disc_loss_total += disc_loss\n",
    "        \n",
    "    # Calculate the time taken for the epoch\n",
    "    time_taken = time.time() - start_time\n",
    "\n",
    "    # If the epoch number is a multiple of 10, save a checkpoint\n",
    "    if (e + 1) % 10 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    # Print the epoch number, average generator loss, average discriminator loss, and time taken\n",
    "    # print('Epoch {}: gen loss: {}, disc loss: {}, time: {:.2f}s'.format(\n",
    "    #     e + 1, gen_loss_total / BATCH_SIZE, disc_loss_total / BATCH_SIZE, time_taken))\n",
    "    print(f'Epoch {e + 1}: gen loss: {gen_loss_total / BATCH_SIZE}, disc loss: {disc_loss_total / BATCH_SIZE}, time: {time_taken:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of samples to generate\n",
    "n_samples = 150\n",
    "# Generate colorized versions of the first n_samples grayscale images in the test set\n",
    "Y_hat = generator(X_test[:n_samples])\n",
    "\n",
    "# Define the number of rows in the grid, which is equal to the number of samples\n",
    "num_rows = len(Y_hat)\n",
    "\n",
    "# Define the number of columns in the grid and the size of each image\n",
    "num_cols = 3  # Number of columns in the grid\n",
    "img_size = 1  # Size of each image in the grid\n",
    "\n",
    "# Create a grid of subplots with num_rows rows and num_cols columns\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * img_size, num_rows * img_size))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.1)  # Adjust spacing between subplots\n",
    "\n",
    "# Loop over the grayscale images, original color images, and colorized images\n",
    "for row, (x, y, y_hat) in enumerate(zip(X_test[:n_samples], Y_test[:n_samples], Y_hat)):\n",
    "\n",
    "    # Convert the original color image from Lab to RGB\n",
    "    orig_lab = np.dstack((x, y * 128))\n",
    "    orig_rgb = lab2rgb(orig_lab)\n",
    "\n",
    "    # Convert the grayscale image from Lab to RGB\n",
    "    grayscale_lab = np.dstack((x, np.zeros((IMAGE_SIZE, IMAGE_SIZE, 2))))\n",
    "    grayscale_rgb = lab2rgb(grayscale_lab)\n",
    "\n",
    "    # Convert the colorized image from Lab to RGB\n",
    "    predicted_lab = np.dstack((x, y_hat * 128))\n",
    "    predicted_rgb = lab2rgb(predicted_lab)\n",
    "    \n",
    "    # Display the grayscale image in the first column of the current row\n",
    "    ax = axes[row, 0]  # Get the appropriate axis for the current subplot\n",
    "    ax.axis('off')  # Turn off axis labels\n",
    "    ax.imshow(grayscale_rgb)\n",
    "    ax.set_title('Grayscale')\n",
    "\n",
    "    # Display the original color image in the second column of the current row\n",
    "    ax = axes[row, 1]  # Move to the next column for original RGB\n",
    "    ax.axis('off')\n",
    "    ax.imshow(orig_rgb)\n",
    "    ax.set_title('Original')\n",
    "\n",
    "    # Display the colorized image in the third column of the current row\n",
    "    ax = axes[row, 2]  # Move to the next column for predicted colorized image\n",
    "    ax.axis('off')\n",
    "    ax.imshow(predicted_rgb)\n",
    "    ax.set_title('Predicted')\n",
    "\n",
    "    # Print the current row number to the console\n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.write('\\r{} / {}'.format(row + 1, num_rows))\n",
    "\n",
    "# Hide empty subplots if any\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        if not ax.has_data():\n",
    "            ax.axis('off')\n",
    "\n",
    "# Adjust the padding between subplots\n",
    "plt.tight_layout(pad=0.5)\n",
    "# Save the figure as an image file\n",
    "plt.savefig(os.path.join(WORKDIR, 'results', 'image_grid.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Generator and Discriminator Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the checkpoints of the models and optimizers so that they can be loaded later\n",
    "# Save the generator model in the SavedModel format\n",
    "tf.saved_model.save(generator, os.path.join(WORKDIR, \"generator-saved-model\"))\n",
    "\n",
    "# Save the discriminator model in the SavedModel format\n",
    "tf.saved_model.save(discriminator, os.path.join(WORKDIR, \"disciminator-saved-model\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
