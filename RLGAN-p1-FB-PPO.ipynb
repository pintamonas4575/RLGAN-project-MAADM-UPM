{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import gymnasium as gym\n",
    "import flappy_bird_gymnasium\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gymnasium.wrappers.rendering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\workspace\\RLGAN-project-MAADM-UPM\\.venv_torch\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "c:\\Users\\aleja\\workspace\\RLGAN-project-MAADM-UPM\\.venv_torch\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 1 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 2 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 3 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 4 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 5 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 6 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 7 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 8 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "Iteration 9 trained; model saved in results_p1/flappy_bird_PPO_10_10000\n",
      "*******Tiempo entreno: 2 minutos y 59.15 segundos*******\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "env = gym.make(\"FlappyBird-v0\")\n",
    "model = PPO(\"MlpPolicy\", env, device=device)\n",
    "\n",
    "n_iters = 10\n",
    "timesteps = 10000\n",
    "name_to_save = f\"results_p1/flappy_bird_PPO_{n_iters}_{timesteps}\"\n",
    "start = time.time()\n",
    "for iter in range(n_iters):\n",
    "        model.learn(total_timesteps=timesteps, reset_num_timesteps=False)\n",
    "        model.save(f\"{name_to_save}\")\n",
    "        print(f\"Iteration {iter} trained; model saved in {name_to_save}\")\n",
    "\n",
    "minutos, segundos = divmod(time.time()-start, 60)\n",
    "print(f\"*******Tiempo entreno: {int(minutos)} minutos y {segundos:.2f} segundos*******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Reward: 43.9\n",
      "Episode 1: Reward: 91.3\n",
      "Episode 2: Reward: 20.0\n",
      "Episode 3: Reward: 56.1\n",
      "Episode 4: Reward: 93.3\n",
      "Episode 5: Reward: 37.2\n",
      "Episode 6: Reward: 54.4\n",
      "Episode 7: Reward: 46.7\n",
      "Episode 8: Reward: 34.6\n",
      "Episode 9: Reward: 18.8\n",
      "Mean reward: 49.629999999999995\n"
     ]
    }
   ],
   "source": [
    "num_episodes_test = 10\n",
    "destiny_folder = \"results_p1/videos\"\n",
    "test_env = gym.make(\"FlappyBird-v0\", render_mode=\"rgb_array\")\n",
    "test_env = Monitor(test_env)\n",
    "test_env = RecordVideo(test_env, video_folder=destiny_folder, name_prefix=\"FB-PPO\", episode_trigger=lambda x: x < num_episodes_test)  \n",
    "\n",
    "test_model = PPO.load(name_to_save, device=device)\n",
    "episode_rewards, episode_lenghts = evaluate_policy(test_model, test_env, n_eval_episodes=num_episodes_test, return_episode_rewards=True)\n",
    "for i, reward in enumerate(episode_rewards):\n",
    "    print(f\"Episode {i}: Reward: {reward}\")\n",
    "print(f\"Mean reward: {sum(episode_rewards)/num_episodes_test}\")\n",
    "\n",
    "test_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
